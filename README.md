Попытка реализовать обучение модели для детекции речи
# Архитектура #
Опираясь в основном на статьи DOI:10.1109/ICASSP.2013.6637694, https://github.com/nicklashansen/voice-activity-detection а так же на статьи в папке articles было принято решение реализовать LSTM сеть, так как в статьях часто показывается, что она работает достаточно быстро, показывает высокую устойчиваость к шуму и высокую точноссть превышающую статистические методы.

Для обучение и работы сети из временного окна размером 10мс по заданию (в статье 25мс) извлекаются MFCC(https://habr.com/ru/post/140828/) и их производные (по 12 штук), в результате имеем 24 фичи. опираясь на DOI:10.1109/ICASSP.2013.6637694 была предпринята неудачная (как оказалось по результатам) попытка создать сеть имеющую один скрытый слой, состоящий из 4 блоков по 50 lstm cells и линейный уровень после. В https://github.com/nicklashansen/voice-activity-detection использовалась функция потерь FocalLoss с параметром гамма = 2, но у меня не получилось обучить с ней сеть (не смог отдебажить) потому использовалась бинарная кроссэнтропия. Опираясь на DOI:10.1109/ICASSP.2013.6637694 обучение происходило в 40 эпох, batchsize =50 (опираясь на гит выше). 

P.S. Датасет оказался слишком большим, но его генерация происходит в соотв. ноутбуке и занимает порядка часа.

# Получение датасета#

Был использован и повторен подход из  https://github.com/nicklashansen/voice-activity-detection. Использовался рекомендованный датасет с чистым голосом без шумов. Из датасета QUT-noises (https://research.qut.edu.au/saivt/databases/qut-noise-databases-and-protocols/) были взяты, нормализованы и наложены рандомно на записи чистого голоса в трех разных интенсивностях (None, -3dB, -15dB). Получение меток для обучения было проведено с помощью бейслайн модели webrtc до наложения шума, которая на чистой речи достойно показывает себя.

Полученный датасет сохранен в data.hdf5 и из него получен датасет для обучения в соответсвующем ноутбуке. Датасет не перемешивается, так как для обучения важно подавать данные для обучения в заданной последовательности, чтобы воспользоваться особенностью LSTM сетей, связанной с запоминанием паттернов. Для ускорения обучения были взяты 10% датасета. Обучить нормально на колабе я не успел :( (а локальная карта не поддерживает cuda).

# Релевантные методы #

В большинстве статей используются нейросети основанные на CNN, и производных RNN: GNN, LSTM. Так же есть статистические методы основанные на спектральном и энергетическом анализе сигнала, но они имеют очень низкую устойчивость к шуму.

# Результаты #

финальная точность моего классификатора составила 0.48 что сравнимо со случайным выбором. Скорее всего это случилось из-за неправильно прописанной сети в связи с малым опытом использования pyTorch. В связи с этим нет смысла классифицировать тестовый датасет, так как это не будет иметь не какого статистического веса. Отдебажить его я, к сожалению, не успел. В конце ноутбука с обучением приведено сравнение с бейслайн моделью (WEBRTC) где видно, что не смотря на большое количество ложноположительных срабатываний (тишина с шумом считается речью) он все еще работает лучше моего классификатора.
